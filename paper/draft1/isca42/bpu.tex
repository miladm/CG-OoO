\subsubsection{Branch Prediction Access}

To avoid fetch bubbles in the instruction flow stream, in conventional
processors, BPU is accessed immediately after every fetch, prior to decoding the
instruction types~\cite{ref:EV8}. On average, this creates 2x extra lookups to
the BPU, exposes the BPU to unnecessary aliasing mis-speculations, and causes
extra energy overhead.

Ahead BPU lookup can prevent accessing the BPU on every instruction. In this
work, once the decode stage detects a new basic-block \texttt{Head} instruction,
    BB Scheduler allocates a new BB Window to the upcoming fetched instructions
    and uses the BR ADDR field in \texttt{Head} to lookup the next basic-block
    destination in BPU (see Figure~\ref{fig:bb_arch}). Since \texttt{Head} comes
    before the branch instruction, ahead prediction avoid bubbles in fetch while
    reducing the average number of BPU lookups by up to 2x improving energy and
    prediction accuracy.

%how often H and BR are fetched together? should we keep the branch offset?

[ADD A DISCUSSION ON HOW GLOBAL READ OPERANDS ARE HANDLED]
